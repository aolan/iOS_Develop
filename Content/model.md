> 以下内容也是通过AI大模型输出的内容，不一定完全正确。

# 1. 名称解释

1.1 LLM （Large Language Model）：它是一种基于海量文本数据训练的人工智能模型，核心能力是理解和生成人类语言。其工作原理是通过深层神经网络（如 Transformer 架构）学习语言中的语法、语义、逻辑关系乃至复杂的知识，从而能够完成文本生成、翻译、问答、摘要、情感分析等多种自然语言处理任务。

1.2 MLLM（Multimodal Large Language Model）: 它是在传统大语言模型（LLM）的基础上发展而来的进阶形态，核心特点是能够同时处理和理解不同类型的模态数据，包括文本、图像、音频、视频等，并实现跨模态的信息融合和生成。

1.3 B：模型参数单位，在衡量大语言模型尺寸时，“B” 是 “Billion”（十亿）的缩写，代表模型的参数数量单位。例如一个 “7B” 模型，指的是该模型包含 70 亿个参数。

1.4 GPT（Generative Pre-trained Transformer）生成式预训练 Transformer 解码器架构，通过预测文本序列的下一个 Token 实现生成任务。


# 2. 市场上常见模型

## 2.1 openAI 公司

以 “GPT” 开头的模型，是基础的对话模型，如 GPT-3.5、GPT-4 等。以 “o” 开头的模型，是推理模型，如 o1、o3 等。以 “o” 结尾的模型，是多模态模型，可处理文本、图像等信息，如 GPT-4o。模型名称后面加上 mini、nano、pro 等，代表不同参数大小，如 GPT-4.1 mini、GPT-4.1 nano。还可能加上 low/medium/high，代表思考的努力程度。

### 2.1.1 GPT-1
OpenAI于2018年发布了GPT-1模型，这是基于生成式预训练（Generative Pre-Training）的Transformer架构，采用了仅有解码器的Transformer模型，专注于预测下一个词元。

### 2.1.2 GPT-2
OpenAI于2019年2月发布了GPT-2模型，继承了GPT-1的架构，并将参数规模扩大到15亿，使用大规模网页数据集WebText进行预训练。
 
### 2.1.3 GPT-3
1. 简介
  * OpenAI 于 2020 年发布的第三代生成式预训练语言模型，属于基于 Transformer 架构的自回归语言模型。
  * 其核心设计理念是通过海量文本数据的无监督预训练，学习语言的统计规律和语义关系，从而具备通用的自然语言处理能力。
  * GPT-3首次提出了“上下文学习”概念，允许大语言模型通过少样本学习解决各种任务，消除了对新任务进行微调的需求。
  * 是大语言模型发展史上的里程碑，其技术突破与局限性共同推动了行业对 AI 伦理、可解释性和可持续性的深入思考。
2. 优势
  * `参数量与泛化能力的突破` 1750亿参数规模，在 2020 年成为全球最大的语言模型，显著提升语义理解和复杂推理能力。例如，在少样本学习中，仅需提供几个示例即可完成代码生成、创意写作等任务。无需标注数据即可处理新任务。例如，输入 “解释量子力学的基本概念”，GPT-3 可直接生成结构化回答，准确率较前代模型提升 40% 以上
  * `多领域适应性与生成多样性` 覆盖文本生成、问答、翻译、代码补全等 80 + 任务。例如，在医疗场景中，可根据症状描述生成鉴别诊断建议。支持小说、诗歌、剧本等体裁的创作。其生成的新闻文章甚至能通过人类评估者的真假判别测试。
  * `上下文理解与长文本处理`  支持处理约 1500 字的长文本，能捕捉复杂的语义依赖关系。例如，在分析法律条款时，可关联前后文条款进行逻辑推理。动态调整注意力范围，优先关注关键信息（如技术文档中的术语定义），减少冗余计算。
  * `少样本学习的标杆性` 通过自然语言指令（如 “请用简洁的语言总结以下内容”）即可引导模型完成任务。例如，在数学推理中，添加 “让我们一步一步地思考” 提示词，可使零样本准确率从 17% 提升至 70% 以上
3. 不足
  * 生成内容的可靠性问题
  * 计算资源与部署成本
  * 可解释性与可控性缺失
  * 数据偏见与社会影响
  * `实时信息与动态适应不足` 训练数据截止到 2021 年，无法处理 2022 年后的新事件（如俄乌冲突、新科技突破）。

### 2.1.4 InstructGPT 
2022 年 1 月发布，基于 GPT-3，开创性地使用基于人类反馈的强化学习（RLHF）进行对齐，让模型输出更符合人类意图。

### 2.1.5 ChatGPT
基于 GPT-3.5 系列模型优化的 ChatGPT 于 2022 年 11 月发布，是 InstructGPT 的迭代版本，通过易用的对话式 Web 界面，将 AI 能力普及给全球用户。

### 2.1.6 GPT-4
1. 简介
  * 2023 年 3 月发布，为`大规模多模态模型`，可接受文本和图像输入并输出文本，深度推理和解决复杂问题的能力远超前代。
2. 优势：
   * `多模态交互能力` GPT-4 支持文本与图像的混合输入，例如能解析包含图表、截图的文档，并生成自然语言或代码回应。在视觉基准测试中，其 VQAv2 任务准确率达 77.2%（0 样本），远超同类模型如 Flamingo（67.6%）。例如，用户上传一张 VGA 充电器图片，它能逐帧分析其中的幽默元素（如过时接口与现代设备的反差）。
   * `复杂逻辑推理和专业能力` 在模拟律师资格考试中，GPT-4 的成绩位列前 10%，而前代 GPT-3.5 仅处于后 10%。它还能处理数学证明、代码调试等任务，例如在 SWE-bench Verified 编程测试中得分 80.2%，被企业用于全栈项目开发。
   * `上下文理解与生成质量` 模型参数规模达 1.8 万亿，训练数据涵盖 13 万亿 token，能捕捉语言中的细微语义关联。例如，在学术问答中，它能基于上下文延伸知识范畴，用类比等手法解释复杂概念（如医学常识），而 GPT-3.5 可能出现 “瞎编” 现象。
   * `任务泛化与适应能力` 通过迁移学习，GPT-4 可快速适配新领域。例如，在少样本提示下，它能生成符合特定格式的教学内容（如中英文对比翻译、题型设计），且结构清晰、逻辑连贯
3. 不足
   * `生成内容的可靠性存疑` 尽管准确率提升，GPT-4 仍可能编造信息。例如，在处理包含 27 个否定符号的逻辑命题时，它误判否定次数，并错误简化表达式
   * `计算资源与成本高昂` 训练需 2.15×10²⁵ 次浮点运算，使用约 2.5 万块 A100 GPU，耗时 3-4 个月，成本超过 6300 万美元。推理时，单次前向传播需 560 TFLOPs 计算量，导致响应延迟较高，且企业部署成本巨大
   * `数据偏见与隐私风险` 训练数据包含互联网文本，可能反映性别、种族等刻板印象。在上下文学习中，模型可能泄露训练数据中的敏感信息（如 Enron 邮件地址），或对话历史中的私人内容
   * `实时性与动态适应局限`GPT-4 依赖离线训练，无法直接处理实时数据（如 2025 年的最新事件）。例如，在旅行行程生成中，它可能忽略景点间的实际距离和交通时间，导致方案缺乏可行性。
   * `推理能力的边界争议` 部分研究指出，GPT-4 的推理本质是 “模式匹配”，而非真正的逻辑推导。例如，在处理包含 27 个否定符号的命题时，它无法正确计数，仅通过表面规律简化问题。其数学推理准确率（如算术运算）仍低于人类水平，需依赖第三方工具弥补。
### 2.1.7 GPT-4V
### 2.1.8 GPT-4 Turbo
### 2.1.9 GPT-4o
### 2.1.10 GPT-4o mini
### 2.1.11 openAI o1
### 2.1.12 Sora
### 2.1.13 Canvas
### 2.1.14 OpenAI o3
### 2.1.15 OpenAI o4-mini


## 2.2 GPT-4.o

## 2.2 微软Copilot
1. 模型类型：MLLM
2. 厂商：微软基于 OpenAI 的 GPT-4、GPT-4o 等大语言模型（LLM），并结合微软自研的语义理解和多模态技术microsoft。
3. 优势：
   * `深度集成生态`  与 Office 套件、Windows 系统、Teams 等微软产品无缝结合，可直接在 Word 中生成报告、在 Excel 中自动化数据分析，或在 PPT 中调用 GPT-4o 生成图片和视频。
   * `上下文理解能力` 通过分析用户历史对话、文档内容和企业数据，提供个性化建议。例如，365 Copilot 可根据会议记录自动生成待办事项
   * `多模态交互` 支持文本、图像、表格等混合输入，例如直接上传设计图生成前端代码，或通过语音指令执行任务 
   * `` 
4. 不足
   * `` 
   * `` 

## 2.3 Github Copilot
1. 模型类型：MLLM
2. 描述：GitHub 与 OpenAI 合作开发，核心技术基于 OpenAI 的 Codex 模型（GPT-3 的代码优化版本），并支持 Claude 3.5 Sonnet、GPT-4o 等大型语言模型。目前看github网站，已经支持 GPT-4.1 和 GPT-4.o
3. 优势：
   * `代码生成效率` 在 VS Code、JetBrains 等 IDE 中提供实时代码补全，平均减少 40% 的编码时间。例如，输入注释 “# 生成快速排序算法” 后，可自动生成完整代码。
   * `多语言支持` 覆盖 Python、Java、C# 等数十种编程语言，甚至支持 Markdown 文档生成和测试用例生成。
   * `上下文感知` 分析项目结构、变量定义和依赖关系，生成符合项目风格的代码。例如，在 React 项目中自动补全组件生命周期方法
4. 不足
   *  `代码质量参差不齐` 生成的代码可能存在逻辑错误、安全漏洞或冗余。例如，生成的 SQL 查询可能未使用参数化查询，导致 SQL 注入风险
   *  `依赖联网环境` 核心模型运行在云端，离线状态下无法使用，且部分企业因数据合规要求无法接入
   *  `复杂任务成功率有限` 尽管 2025 年推出 “Agent Mode” 支持多步骤代码生成（如自动提交 PR），但在硬难度问题上成功率仍不足 50%

## 2.3 Cursor
1. 模型类型：MLLM
2. 厂商：Microsoft
3. 优势：
   * `` 
   * ``
   * `` 
   * `` 
4. 不足
   * `` 
   * `` 

## 2.3 Ferret-UI
1. 模型类型：MLLM
2. 厂商：是苹果公司推出的多模态大语言模型（MLLM），专门针对移动用户界面（UI）屏幕的理解进行了优化，具备引用、定位和推理能力。
3. 优势：
   * `智能理解用户意图`  不同于传统基于坐标点击的操作方式，Ferret-UI 能够根据用户的自然语言指令，自动定位并执行相应操作。
   * `跨平台适配` Ferret-UI2 可在 iPhone、iPad、安卓设备、网页浏览器和 Apple TV 等多个平台上准确识别 UI 元素。在 iPhone 端运行流畅，iPad 端准确率达 68%，安卓设备上的成功率达到 71%。
   * `高分辨率自适应` 可以适应不同分辨率的屏幕，能精准识别屏幕上的按钮、图标和文本等元素，在高清大屏或手机小屏上都能保持较好的 UI 识别效果。
   * `性能表现优异` 在 UI 元素识别方面表现出色，测试得分达 89.73，大幅领先 GPT-4V 的 77.73 分，在初级 UI 任务中超越了 GPT-4V，在包含高级任务的全任务平均得分与 GPT-4V 非常相近。
4. 不足
   * `` 
   * `` 

# 3. 大模型头部厂商

# 4. 大模型工具

# 5. 端侧模型


